{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165ecc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (0.19.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hitham\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\hitham\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (2.11.9)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: cloudpickle>=2.2.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from srsly<3.0.0,>=2.4.3->spacy) (3.1.1)\n",
      "Requirement already satisfied: ujson>=1.35 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from srsly<3.0.0,>=2.4.3->spacy) (5.11.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hitham\\appdata\\roaming\\python\\python310\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\hitham\\appdata\\roaming\\python\\python310\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\bam3034\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d1f64d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Install spaCy and download the English model if not already installed\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example text\n",
    "text = \"spaCy is an amazing NLP library for Python! It can perform tokenization, POS tagging, and named entity recognition.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"-\"*40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3814cd8e-1a0d-4392-9dae-ddbb338b5489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tokenization, POS, and Dependency Parsing ===\n",
      "spaCy           POS: NUM        Dep: nsubj\n",
      "is              POS: AUX        Dep: ROOT\n",
      "an              POS: DET        Dep: det\n",
      "amazing         POS: ADJ        Dep: amod\n",
      "NLP             POS: PROPN      Dep: compound\n",
      "library         POS: NOUN       Dep: attr\n",
      "for             POS: ADP        Dep: prep\n",
      "Python          POS: PROPN      Dep: pobj\n",
      "!               POS: PUNCT      Dep: punct\n",
      "It              POS: PRON       Dep: nsubj\n",
      "can             POS: AUX        Dep: aux\n",
      "perform         POS: VERB       Dep: ROOT\n",
      "tokenization    POS: NOUN       Dep: dobj\n",
      ",               POS: PUNCT      Dep: punct\n",
      "POS             POS: PROPN      Dep: compound\n",
      "tagging         POS: NOUN       Dep: conj\n",
      ",               POS: PUNCT      Dep: punct\n",
      "and             POS: CCONJ      Dep: cc\n",
      "named           POS: VERB       Dep: conj\n",
      "entity          POS: NOUN       Dep: compound\n",
      "recognition     POS: NOUN       Dep: oprd\n",
      ".               POS: PUNCT      Dep: punct\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Tokenization with Part-of-speech and Dependency Parsing\n",
    "print(\"=== Tokenization, POS, and Dependency Parsing ===\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:15} POS: {token.pos_:10} Dep: {token.dep_}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544fdc91-d9d9-497e-8a5c-b238221130d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Named Entities ===\n",
      "Entity: NLP                  Label: ORG\n",
      "Entity: Google               Label: ORG\n",
      "Entity: September 1998       Label: DATE\n",
      "Entity: Larry Page           Label: PERSON\n",
      "Entity: Sergey Brin          Label: PERSON\n",
      "Entity: Ph.D.                Label: WORK_OF_ART\n",
      "Entity: Stanford University  Label: ORG\n",
      "Entity: California           Label: GPE\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Named Entity Recognition (NER)\n",
    "print(\"=== Named Entities ===\")\n",
    "text = \"spaCy is an amazing NLP library for Python! It can perform tokenization, POS tagging, and named entity recognition. Google was founded in September 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text:20} Label: {ent.label_}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f90314d9-ce4c-41a4-b819-5cb0905f5a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Lemmatization ===\n",
      "spaCy           Lemma: spacy\n",
      "is              Lemma: be\n",
      "an              Lemma: an\n",
      "amazing         Lemma: amazing\n",
      "NLP             Lemma: NLP\n",
      "library         Lemma: library\n",
      "for             Lemma: for\n",
      "Python          Lemma: Python\n",
      "!               Lemma: !\n",
      "It              Lemma: it\n",
      "can             Lemma: can\n",
      "perform         Lemma: perform\n",
      "tokenization    Lemma: tokenization\n",
      ",               Lemma: ,\n",
      "POS             Lemma: POS\n",
      "tagging         Lemma: tagging\n",
      ",               Lemma: ,\n",
      "and             Lemma: and\n",
      "named           Lemma: name\n",
      "entity          Lemma: entity\n",
      "recognition     Lemma: recognition\n",
      ".               Lemma: .\n",
      "Google          Lemma: Google\n",
      "was             Lemma: be\n",
      "founded         Lemma: found\n",
      "in              Lemma: in\n",
      "September       Lemma: September\n",
      "1998            Lemma: 1998\n",
      "by              Lemma: by\n",
      "Larry           Lemma: Larry\n",
      "Page            Lemma: Page\n",
      "and             Lemma: and\n",
      "Sergey          Lemma: Sergey\n",
      "Brin            Lemma: Brin\n",
      "while           Lemma: while\n",
      "they            Lemma: they\n",
      "were            Lemma: be\n",
      "Ph.D.           Lemma: ph.d.\n",
      "students        Lemma: student\n",
      "at              Lemma: at\n",
      "Stanford        Lemma: Stanford\n",
      "University      Lemma: University\n",
      "in              Lemma: in\n",
      "California      Lemma: California\n",
      ".               Lemma: .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Lemmatization\n",
    "print(\"=== Lemmatization ===\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:15} Lemma: {token.lemma_}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e2a6000-2e5a-4d1b-b404-00a17ec740f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sentences ===\n",
      "spaCy is an amazing NLP library for Python!\n",
      "It can perform tokenization, POS tagging, and named entity recognition.\n",
      "Google was founded in September 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Sentence Segmentation\n",
    "print(\"=== Sentences ===\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c8a68cc-67e9-49f4-bd80-017485d545af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stop Word Removal ===\n",
      "Filtered Tokens: ['spaCy', 'amazing', 'NLP', 'library', 'Python', '!', 'perform', 'tokenization', ',', 'POS', 'tagging', ',', 'named', 'entity', 'recognition', '.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Stop Word Removal\n",
    "print(\"=== Stop Word Removal ===\")\n",
    "filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "print(\"Filtered Tokens:\", filtered_tokens)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0921dd2-b7f5-41de-8342-85dd1268c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Parts of Speech (POS) Tagging ===\n",
      "Token           POS        Explanation\n",
      "----------------------------------------\n",
      "spaCy           NUM        numeral\n",
      "is              AUX        auxiliary\n",
      "an              DET        determiner\n",
      "amazing         ADJ        adjective\n",
      "NLP             PROPN      proper noun\n",
      "library         NOUN       noun\n",
      "for             ADP        adposition\n",
      "Python          PROPN      proper noun\n",
      "!               PUNCT      punctuation\n",
      "It              PRON       pronoun\n",
      "can             AUX        auxiliary\n",
      "perform         VERB       verb\n",
      "tokenization    NOUN       noun\n",
      ",               PUNCT      punctuation\n",
      "POS             PROPN      proper noun\n",
      "tagging         NOUN       noun\n",
      ",               PUNCT      punctuation\n",
      "and             CCONJ      coordinating conjunction\n",
      "named           VERB       verb\n",
      "entity          NOUN       noun\n",
      "recognition     NOUN       noun\n",
      ".               PUNCT      punctuation\n",
      "Google          PROPN      proper noun\n",
      "was             AUX        auxiliary\n",
      "founded         VERB       verb\n",
      "in              ADP        adposition\n",
      "September       PROPN      proper noun\n",
      "1998            NUM        numeral\n",
      "by              ADP        adposition\n",
      "Larry           PROPN      proper noun\n",
      "Page            PROPN      proper noun\n",
      "and             CCONJ      coordinating conjunction\n",
      "Sergey          PROPN      proper noun\n",
      "Brin            PROPN      proper noun\n",
      "while           SCONJ      subordinating conjunction\n",
      "they            PRON       pronoun\n",
      "were            AUX        auxiliary\n",
      "Ph.D.           NOUN       noun\n",
      "students        NOUN       noun\n",
      "at              ADP        adposition\n",
      "Stanford        PROPN      proper noun\n",
      "University      PROPN      proper noun\n",
      "in              ADP        adposition\n",
      "California      PROPN      proper noun\n",
      ".               PUNCT      punctuation\n"
     ]
    }
   ],
   "source": [
    "# 6. Parts of Speech Tagging with Explanation\n",
    "print(\"=== Parts of Speech (POS) Tagging ===\")\n",
    "print(f\"{'Token':15} {'POS':10} Explanation\")\n",
    "print(\"-\" * 40)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:15} {token.pos_:10} {spacy.explain(token.pos_)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BAM3034",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
