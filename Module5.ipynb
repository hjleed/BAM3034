{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a1fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07fc5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size_sqft</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>2</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Size_sqft  Bedrooms    Price\n",
       "0        300         2   600000\n",
       "1        400         2   800000\n",
       "2        200         3   600000\n",
       "3        100         3   300000\n",
       "4        500         1  1000000\n",
       "5        500         5   300000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example dataset\n",
    "data = {\n",
    "    \"Size_sqft\": [300, 400, 200, 100, 500, 500],\n",
    "    \"Bedrooms\":  [2,   2,   3,   3, 1, 5],\n",
    "    \"Price\":     [600000, 800000, 600000, 300000, 1000000, 300000],\n",
    "}\n",
    " # y= x1 *  x2 *1000\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b8074f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price for Size=350 sqft, Bedrooms=4: 724396.78\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict  =>  \"Size_sqft\": [350], \"Bedrooms\": [2]\n",
    "\n",
    "\n",
    "\n",
    "# Features and target\n",
    "X = df[[\"Size_sqft\", \"Bedrooms\"]]\n",
    "y = df[\"Price\"]\n",
    "\n",
    "# Train linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "# Test sample\n",
    "test_sample = pd.DataFrame({\"Size_sqft\": [350], \"Bedrooms\": [2]})\n",
    "\n",
    "# Prediction\n",
    "predicted_price = model.predict(test_sample)\n",
    "print(f\"Predicted Price for Size=350 sqft, Bedrooms=4: {predicted_price[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8156ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "   Size_sqft  Bedrooms  Actual Price  Predicted Price\n",
      "1        900         2        270000        198842.98\n",
      "5       2500         4        500000        454462.81\n",
      "0        850         2        250000        196446.28\n",
      "\n",
      "Mean Squared Error: 3334986225.8953176\n",
      "Root Mean Squared Error: 57749.33961436544\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    \"Size_sqft\": [850, 900, 1200, 1500, 2000, 2500, 3000, 3500],\n",
    "    \"Bedrooms\": [2, 2, 3, 3, 4, 4, 5, 5],\n",
    "    \"Price\": [250000, 270000, 300000, 310000, 450000, 500000, 550000, 600000],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target\n",
    "X = df[[\"Size_sqft\", \"Bedrooms\"]]\n",
    "y = df[\"Price\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Combine test data with predictions\n",
    "results = X_test.copy()\n",
    "results[\"Actual Price\"] = y_test\n",
    "results[\"Predicted Price\"] = y_pred.round(2)\n",
    "\n",
    "print(\"Test Results:\")\n",
    "print(results)\n",
    "print(\"\\nMean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086636e3",
   "metadata": {},
   "source": [
    "![alt text](https://www.statlect.com/images/decision-tree-structure.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aebd9d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.8812908992306927\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(labels):\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "# Example dataset (7 good, 3 bad)\n",
    "labels = ['g','g','g','g','g','g','g','b','b','b']\n",
    "print(\"Entropy:\", entropy(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7e1993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain: 0.2812908992306927\n"
     ]
    }
   ],
   "source": [
    "def information_gain(parent, left_child, right_child):\n",
    "    weight_left = len(left_child) / len(parent)\n",
    "    weight_right = len(right_child) / len(parent)\n",
    "    \n",
    "    return entropy(parent) - (\n",
    "        weight_left * entropy(left_child) +\n",
    "        weight_right * entropy(right_child)\n",
    "    )\n",
    "\n",
    "parent = ['g','g','g','g','g','g','g','b','b','b']\n",
    "left_child = ['g','g','g','g']\n",
    "right_child = ['g','g','g','b','b','b']\n",
    "\n",
    "print(\"Information Gain:\", information_gain(parent, left_child, right_child))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4c66a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- Years <= 6.50\n",
      "|   |--- Years <= 2.50\n",
      "|   |   |--- class: 1\n",
      "|   |--- Years >  2.50\n",
      "|   |   |--- class: 0\n",
      "|--- Years >  6.50\n",
      "|   |--- class: 1\n",
      "\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    'Name': ['Mike', 'Mary', 'Bill', 'Jim', 'Dave', 'Anne'],\n",
    "    'Rank': ['Assistant Prof', 'Assistant Prof', 'Professor', 'Associate Prof', 'Assistant Prof', 'Associate Prof'],\n",
    "    'Years': [3, 7, 2, 7, 6, 3],\n",
    "    'Tenured': ['no', 'yes', 'yes', 'yes', 'no', 'no']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode\n",
    "le_rank = LabelEncoder()\n",
    "df['Rank_encoded'] = le_rank.fit_transform(df['Rank'])\n",
    "le_ten = LabelEncoder()\n",
    "y = le_ten.fit_transform(df['Tenured'])\n",
    "X = df[['Years', 'Rank_encoded']]  # Order affects tie-breaking in Scikit-learn\n",
    "\n",
    "# Train\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Tree structure\n",
    "print(export_text(clf, feature_names=['Years', 'Rank_encoded']))\n",
    "\n",
    "# Predict Jeff\n",
    "rank_prof = le_rank.transform(['Professor'])[0]\n",
    "X_test = pd.DataFrame({'Years': [4], 'Rank_encoded': [rank_prof]})\n",
    "pred = clf.predict(X_test)\n",
    "print(le_ten.inverse_transform(pred)[0])  # Output: 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b953bb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "Prediction (1=Python, 0=Java): 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "documents = [\n",
    "    'I love programming in Python',\n",
    "    'Python is great for machine learning',\n",
    "    'I hate programming in Java',\n",
    "    'Java is a versatile language',\n",
    "    'I am learning data science with Python',\n",
    "    'Java is mostly used in enterprise applications',\n",
    "    'Python is easy to learn',\n",
    "    'I dislike Java because of its verbosity'\n",
    "]\n",
    "\n",
    "labels = [1, 1, 0, 0, 1, 0, 1, 0]\n",
    "\n",
    "# Convert text to numerical features\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Decision Tree\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Test new sentence\n",
    "new_text = [\"I am learning Java for enterprise applications\"]\n",
    "new_vector = vectorizer.transform(new_text)\n",
    "prediction = model.predict(new_vector)\n",
    "\n",
    "print(\"Prediction (1=Python, 0=Java):\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae75c84",
   "metadata": {},
   "source": [
    "## Multinomial Naïve Bayes (Text Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31819b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.75      0.75      0.67         3\n",
      "weighted avg       0.83      0.67      0.67         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "nb_pred = nb_model.predict(X_test)\n",
    "print(\"Naïve Bayes Report:\\n\", classification_report(y_test, nb_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3de914",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bc20049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.75      0.75      0.67         3\n",
      "weighted avg       0.83      0.67      0.67         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "print(\"SVM Report:\\n\", classification_report(y_test, svm_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BAM3034",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
